{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b3284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "FILE_PATH = \"Chronic_Kidney_Disease_data.csv\"\n",
    "\n",
    "NOISE_FACTOR = 0.05  \n",
    "TARGET_COLUMN = 'Diagnosis' \n",
    "\n",
    "CONTINUOUS_COLS = [\n",
    "    'Age', 'BMI', 'SystolicBP', 'DiastolicBP', 'FastingBloodSugar', 'HbA1c',\n",
    "    'SerumCreatinine', 'BUNLevels', 'GFR', 'HemoglobinLevels', \n",
    "    'CholesterolTotal', 'CholesterolLDL', 'CholesterolHDL', 'CholesterolTriglycerides',\n",
    "    'SerumElectrolytesSodium', 'SerumElectrolytesPotassium', \n",
    "    'SerumElectrolytesCalcium', 'SerumElectrolytesPhosphorus'\n",
    "]\n",
    "\n",
    "DISCRETE_COLS = [\n",
    "    'Gender', 'Ethnicity', 'SocioeconomicStatus', 'EducationLevel', 'Smoking', 'AlcoholConsumption', \n",
    "    'PhysicalActivity', 'DietQuality', 'SleepQuality', 'FamilyHistoryKidneyDisease', \n",
    "    'FamilyHistoryHypertension', 'FamilyHistoryDiabetes', 'PreviousAcuteKidneyInjury', \n",
    "    'UrinaryTractInfections', 'ACEInhibitors', 'Diuretics', 'NSAIDsUse', \n",
    "    'Statins', 'AntidiabeticMedications', 'Edema', 'FatigueLevels', 'NauseaVomiting', \n",
    "    'MuscleCramps', 'Itching', 'ProteinInUrine', 'ACR', \n",
    "    'WaterQuality', 'MedicalCheckupsFrequency', 'MedicationAdherence', 'HealthLiteracy'\n",
    "] \n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    " \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}. Please ensure the file is available.\")\n",
    "        return None\n",
    "\n",
    "    if TARGET_COLUMN in df.columns:\n",
    "        df.dropna(subset=[TARGET_COLUMN], inplace=True)\n",
    "        df = df[df[TARGET_COLUMN].astype(str).str.lower() != 'confidential']\n",
    "        \n",
    "        unique_labels = df[TARGET_COLUMN].astype(str).unique()\n",
    "        \n",
    "        if len(unique_labels) >= 2:\n",
    "            label_counts = df[TARGET_COLUMN].value_counts().sort_values(ascending=False)\n",
    "            label_map = {label_counts.index[0]: 0, label_counts.index[1]: 1}\n",
    "            df['target'] = df[TARGET_COLUMN].map(label_map)\n",
    "            df.dropna(subset=['target'], inplace=True)\n",
    "            df['target'] = df['target'].astype(int)\n",
    "        else:\n",
    "            print(f\"Error: Could not find two distinct, valid labels in the '{TARGET_COLUMN}' column for binary classification.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Error: Target column '{TARGET_COLUMN}' not found in the file.\")\n",
    "        return None\n",
    "    \n",
    "    df.drop(columns=[TARGET_COLUMN, 'PatientID', 'DoctorInCharge', 'QualityOfLifeScore'], errors='ignore', inplace=True)\n",
    "    \n",
    "    df = df.replace('?', np.nan)\n",
    "    df = df.replace('Confidential', np.nan)\n",
    "\n",
    "    for col in DISCRETE_COLS:\n",
    "        if col not in df.columns: continue\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        mode_val = df[col].mode()[0]\n",
    "        df[col] = df[col].fillna(mode_val).astype(int)\n",
    "\n",
    "    for col in CONTINUOUS_COLS:\n",
    "        if col not in df.columns: continue\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        median_val = df[col].median()\n",
    "        df[col] = df[col].fillna(median_val)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def augment_continuous_features(X_continuous, noise_factor):\n",
    "    std_devs = X_continuous.std(axis=0)\n",
    "    std_devs[std_devs == 0] = 1e-6 \n",
    "    \n",
    "    noise = np.random.normal(loc=0.0, scale=1.0, size=X_continuous.shape)\n",
    "    scaled_noise = noise * std_devs * noise_factor\n",
    "\n",
    "    X_augmented = X_continuous + scaled_noise\n",
    "    return X_augmented\n",
    "\n",
    "def perform_oversampling(df_original):\n",
    "    class_counts = df_original['target'].value_counts()\n",
    "    \n",
    "    TARGET_CLASS_COUNT = class_counts.max()\n",
    "\n",
    "    target_0 = class_counts.index[0]\n",
    "    target_1 = class_counts.index[1]\n",
    "    \n",
    "    df_class_0 = df_original[df_original['target'] == target_0].drop(columns=['target'])\n",
    "    df_class_1 = df_original[df_original['target'] == target_1].drop(columns=['target'])\n",
    "    \n",
    "    n_augment_0 = TARGET_CLASS_COUNT - len(df_class_0)\n",
    "    n_augment_1 = TARGET_CLASS_COUNT - len(df_class_1)\n",
    "    \n",
    "    all_features = CONTINUOUS_COLS + DISCRETE_COLS\n",
    "    \n",
    "    def generate_augmented_data(df_class, n_augment, target_class):\n",
    "        if n_augment <= 0:\n",
    "            return pd.DataFrame() \n",
    "\n",
    "        sample_indices = np.random.choice(len(df_class), size=n_augment, replace=True)\n",
    "        \n",
    "        current_continuous_cols = [col for col in CONTINUOUS_COLS if col in df_class.columns]\n",
    "        current_discrete_cols = [col for col in DISCRETE_COLS if col in df_class.columns]\n",
    "        \n",
    "        X_continuous = df_class[current_continuous_cols].iloc[sample_indices].values\n",
    "        X_discrete = df_class[current_discrete_cols].iloc[sample_indices].values\n",
    "        \n",
    "        X_aug_continuous = augment_continuous_features(X_continuous, NOISE_FACTOR)\n",
    "        \n",
    "        df_aug_continuous = pd.DataFrame(X_aug_continuous, columns=current_continuous_cols)\n",
    "        df_aug_discrete = pd.DataFrame(X_discrete, columns=current_discrete_cols)\n",
    "        \n",
    "        for col in current_discrete_cols:\n",
    "            df_aug_discrete[col] = df_aug_discrete[col].astype(int)\n",
    "        \n",
    "        df_aug = pd.concat([df_aug_continuous, df_aug_discrete], axis=1)\n",
    "        df_aug = df_aug[[col for col in all_features if col in df_aug.columns]]\n",
    "        df_aug['target'] = target_class\n",
    "        return df_aug\n",
    "\n",
    "    df_aug_0 = generate_augmented_data(df_class_0, n_augment_0, target_0)\n",
    "    \n",
    "    df_aug_1 = generate_augmented_data(df_class_1, n_augment_1, target_1)\n",
    "\n",
    "    df_augmented = pd.concat([df_aug_0, df_aug_1], ignore_index=True)\n",
    "    \n",
    "    df_original_with_target = df_original.copy()\n",
    "    df_original_with_target['target'] = df_original['target']\n",
    "    \n",
    "    df_final = pd.concat([df_original_with_target, df_augmented], ignore_index=True)\n",
    "    \n",
    "    return df_final, df_augmented, TARGET_CLASS_COUNT\n",
    "\n",
    "initial_df = load_and_preprocess_data(FILE_PATH)\n",
    "\n",
    "if initial_df is not None:\n",
    "    final_df, augmented_df, target_count = perform_oversampling(initial_df)\n",
    "\n",
    "final_df = final_df.rename(columns={'target': 'class'})\n",
    "final_df.to_csv('CKD_Augmented.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5b09d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_column = 'class'\n",
    "class_counts = df_336[class_column].value_counts().sort_values(ascending=False)\n",
    "labels = class_counts.index\n",
    "sizes = class_counts.values\n",
    "print(\"Lables: \", labels.values)\n",
    "print(\"Sizes: \", sizes)\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.pie(\n",
    "        sizes,\n",
    "        labels=labels,\n",
    "        # Format the percentage to one decimal place\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=90, # Start the first slice at the top\n",
    "        colors=plt.cm.viridis(np.linspace(0, 1, len(labels))), # Use a color map\n",
    "        wedgeprops={'edgecolor': 'black', 'linewidth': 1, 'antialiased': True} # Add borders\n",
    "    )\n",
    "plt.axis('equal')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
