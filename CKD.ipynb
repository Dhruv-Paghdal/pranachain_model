{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24454705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                           f1_score, confusion_matrix, classification_report, roc_auc_score)\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db22f96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "1. LOADING DATA...\n",
      "------------------------------\n",
      "Dataset Shape: (400, 24)\n",
      "Target Shape: (400, 1)\n",
      "Features: ['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wbcc', 'rbcc', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n",
      "Target Classes: ['ckd' 'ckd\\t' 'notckd']\n",
      "Target Classes Count: ckd       248\n",
      "notckd    150\n",
      "ckd\\t       2\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. DATA LOADING\n",
    "print(\"-\"*30)\n",
    "print(\"1. LOADING DATA...\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "# Fetch dataset\n",
    "chronic_kidney_disease = fetch_ucirepo(id=336)\n",
    "\n",
    "# Get features and targets\n",
    "X = chronic_kidney_disease.data.features.copy()\n",
    "y = chronic_kidney_disease.data.targets.copy()\n",
    "\n",
    "print(f\"Dataset Shape: {X.shape}\")\n",
    "print(f\"Target Shape: {y.shape}\")\n",
    "print(f\"Features: {list(X.columns)}\")\n",
    "print(f\"Target Classes: {y['class'].unique()}\")\n",
    "print(f\"Target Classes Count: {y['class'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1517dce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Classes: ['ckd' 'notckd']\n",
      "Target Classes Count: ckd       250\n",
      "notckd    150\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Replacing ckd\\t to ckd\n",
    "\n",
    "# Count problematic rows before cleaning\n",
    "ckd_tab_count = (y['class'] == 'ckd\\t').sum()\n",
    "whitespace_issues = (y['class'] != y['class'].str.strip()).sum()\n",
    "\n",
    "# Clean the class column by stripping whitespace\n",
    "y['class'] = y['class'].str.strip()\n",
    "\n",
    "# Verify cleaning worked\n",
    "print(f\"Target Classes: {y['class'].unique()}\")\n",
    "print(f\"Target Classes Count: {y['class'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad855a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "2. DATA ANALYSIS & EXPLORATION...\n",
      "----------------------------------------\n",
      "Dataset Info:\n",
      "- Total samples: 400\n",
      "- Total features: 24\n",
      "- Target distribution:\n",
      "  • ckd: 250 (62.5%)\n",
      "  • notckd: 150 (37.5%)\n",
      "\n",
      "Missing Values Analysis:\n",
      "Feature  Missing_Count  Missing_Percent Data_Type\n",
      "    rbc            152            38.00    object\n",
      "   rbcc            131            32.75   float64\n",
      "   wbcc            106            26.50   float64\n",
      "    pot             88            22.00   float64\n",
      "    sod             87            21.75   float64\n",
      "    pcv             71            17.75   float64\n",
      "     pc             65            16.25    object\n",
      "   hemo             52            13.00   float64\n",
      "     su             49            12.25   float64\n",
      "     sg             47            11.75   float64\n",
      "     al             46            11.50   float64\n",
      "    bgr             44            11.00   float64\n",
      "     bu             19             4.75   float64\n",
      "     sc             17             4.25   float64\n",
      "     bp             12             3.00   float64\n",
      "    age              9             2.25   float64\n",
      "     ba              4             1.00    object\n",
      "    pcc              4             1.00    object\n",
      "    htn              2             0.50    object\n",
      "     dm              2             0.50    object\n",
      "    cad              2             0.50    object\n",
      "  appet              1             0.25    object\n",
      "     pe              1             0.25    object\n",
      "    ane              1             0.25    object\n",
      "\n",
      "Data Types Summary:\n",
      "- Numeric features (14): ['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wbcc', 'rbcc']\n",
      "- Categorical features (10): ['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n"
     ]
    }
   ],
   "source": [
    "# 2. DATA ANALYSIS & EXPLORATION\n",
    "print(\"-\"*40)\n",
    "print(\"2. DATA ANALYSIS & EXPLORATION...\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Basic info\n",
    "print(\"Dataset Info:\")\n",
    "print(f\"- Total samples: {len(X)}\")\n",
    "print(f\"- Total features: {X.shape[1]}\")\n",
    "print(f\"- Target distribution:\")\n",
    "target_counts = y['class'].value_counts()\n",
    "for cls, count in target_counts.items():\n",
    "    print(f\"  • {cls}: {count} ({count/len(y)*100:.1f}%)\")\n",
    "\n",
    "# Missing values analysis\n",
    "print(\"\\nMissing Values Analysis:\")\n",
    "missing_info = []\n",
    "for col in X.columns:\n",
    "    missing_count = X[col].isnull().sum()\n",
    "    missing_percent = (missing_count / len(X)) * 100\n",
    "    missing_info.append({\n",
    "        'Feature': col,\n",
    "        'Missing_Count': missing_count,\n",
    "        'Missing_Percent': missing_percent,\n",
    "        'Data_Type': str(X[col].dtype)\n",
    "    })\n",
    "\n",
    "missing_df = pd.DataFrame(missing_info)\n",
    "missing_df = missing_df.sort_values('Missing_Percent', ascending=False)\n",
    "print(missing_df.to_string(index=False))\n",
    "\n",
    "# Data types analysis\n",
    "print(f\"\\nData Types Summary:\")\n",
    "numeric_features = []\n",
    "categorical_features = []\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].dtype in ['int64', 'float64']:\n",
    "        numeric_features.append(col)\n",
    "    else:\n",
    "        categorical_features.append(col)\n",
    "\n",
    "print(f\"- Numeric features ({len(numeric_features)}): {numeric_features}\")\n",
    "print(f\"- Categorical features ({len(categorical_features)}): {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d27c01ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "3. DATA CLEANING & PREPROCESSING...\n",
      "----------------------------------------\n",
      "Numeric columns for imputation: ['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wbcc', 'rbcc', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n",
      "Categorical columns for imputation: []\n",
      "Missing values after imputation: 0\n",
      "\n",
      "Feature Engineering...\n",
      "Final feature set: 27 features\n",
      "Feature engineering completed.\n"
     ]
    }
   ],
   "source": [
    "# 3. DATA CLEANING & PREPROCESSING\n",
    "print(\"-\"*40)\n",
    "print(\"3. DATA CLEANING & PREPROCESSING...\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Create a copy for processing\n",
    "X_processed = X.copy()\n",
    "y_processed = y.copy()\n",
    "\n",
    "# Binary mappings\n",
    "binary_mappings = {\n",
    "    'rbc': {'normal': 0, 'abnormal': 1},\n",
    "    'pc': {'normal': 0, 'abnormal': 1},\n",
    "    'pcc': {'notpresent': 0, 'present': 1},\n",
    "    'ba': {'notpresent': 0, 'present': 1},\n",
    "    'htn': {'no': 0, 'yes': 1},\n",
    "    'dm': {'no': 0, 'yes': 1},\n",
    "    'cad': {'no': 0, 'yes': 1},\n",
    "    'appet': {'good': 0, 'poor': 1},\n",
    "    'pe': {'no': 0, 'yes': 1},\n",
    "    'ane': {'no': 0, 'yes': 1}\n",
    "}\n",
    "\n",
    "# Apply binary mappings\n",
    "for feature, mapping in binary_mappings.items():\n",
    "    if feature in X_processed.columns:\n",
    "        X_processed[feature] = X_processed[feature].map(mapping)\n",
    "\n",
    "# Handle ordinal categorical features\n",
    "# Specific gravity - convert to numeric\n",
    "if 'sg' in X_processed.columns:\n",
    "    X_processed['sg'] = pd.to_numeric(X_processed['sg'], errors='coerce')\n",
    "\n",
    "# Albumin and Sugar - already numeric\n",
    "for feature in ['al', 'su']:\n",
    "    if feature in X_processed.columns:\n",
    "        X_processed[feature] = pd.to_numeric(X_processed[feature], errors='coerce')\n",
    "\n",
    "# Convert target to binary\n",
    "y_processed['class'] = y_processed['class'].map({'notckd': 0, 'ckd': 1})\n",
    "\n",
    "print(\"\\nHandling missing values...\")\n",
    "\n",
    "# Separate features by type for different imputation strategies\n",
    "numeric_cols = X_processed.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = X_processed.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "print(f\"Numeric columns for imputation: {list(numeric_cols)}\")\n",
    "print(f\"Categorical columns for imputation: {list(categorical_cols)}\")\n",
    "\n",
    "# For numeric features, use KNN imputation\n",
    "if len(numeric_cols) > 0:\n",
    "    knn_imputer = KNNImputer(n_neighbors=5)\n",
    "    X_processed[numeric_cols] = knn_imputer.fit_transform(X_processed[numeric_cols])\n",
    "\n",
    "# For categorical features (if any remaining), use mode imputation\n",
    "if len(categorical_cols) > 0:\n",
    "    mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    X_processed[categorical_cols] = mode_imputer.fit_transform(X_processed[categorical_cols])\n",
    "\n",
    "print(f\"Missing values after imputation: {X_processed.isnull().sum().sum()}\")\n",
    "\n",
    "# Feature engineering - create some additional features\n",
    "print(\"\\nFeature Engineering...\")\n",
    "\n",
    "# BMI-like indicator using available blood parameters\n",
    "if all(col in X_processed.columns for col in ['hemo', 'pcv']):\n",
    "    X_processed['hemo_pcv_ratio'] = X_processed['hemo'] / (X_processed['pcv'] + 0.001)\n",
    "\n",
    "# Kidney function indicator\n",
    "if all(col in X_processed.columns for col in ['sc', 'bu']):\n",
    "    X_processed['kidney_function_score'] = X_processed['sc'] * X_processed['bu']\n",
    "\n",
    "# Blood pressure category\n",
    "if 'bp' in X_processed.columns:\n",
    "    X_processed['bp_category'] = pd.cut(X_processed['bp'], \n",
    "                                       bins=[0, 90, 120, 140, 200], \n",
    "                                       labels=[0, 1, 2, 3])\n",
    "    X_processed['bp_category'] = X_processed['bp_category'].astype(int)\n",
    "\n",
    "print(f\"Final feature set: {X_processed.shape[1]} features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cff01f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "4. CREATING TRAIN/TEST SPLIT...\n",
      "-----------------------------------\n",
      "Training set: 320 samples\n",
      "Testing set: 80 samples\n",
      "Train class distribution: [120 200]\n",
      "Test class distribution: [30 50]\n"
     ]
    }
   ],
   "source": [
    "# 4. TRAIN/TEST SPLIT\n",
    "print(\"-\"*35)\n",
    "print(\"4. CREATING TRAIN/TEST SPLIT...\")\n",
    "print(\"-\"*35)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y_processed['class'], \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_processed['class']\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
    "print(f\"Train class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Test class distribution: {np.bincount(y_test)}\")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3198c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "5. MODEL TRAINING & EVALUATION...\n",
      "--------------------------------------\n",
      "Training and evaluating models...\n",
      "\n",
      "Training Logistic Regression...\n",
      "  Accuracy: 0.9625\n",
      "  F1-Score: 0.9691\n",
      "  CV Score: 0.9844 ± 0.0171\n",
      "\n",
      "Training Random Forest...\n",
      "  Accuracy: 1.0000\n",
      "  F1-Score: 1.0000\n",
      "  CV Score: 0.9906 ± 0.0125\n",
      "\n",
      "Training Gradient Boosting...\n",
      "  Accuracy: 0.9750\n",
      "  F1-Score: 0.9796\n",
      "  CV Score: 0.9781 ± 0.0234\n",
      "\n",
      "Training SVM...\n",
      "  Accuracy: 0.9875\n",
      "  F1-Score: 0.9899\n",
      "  CV Score: 0.9875 ± 0.0117\n",
      "\n",
      "Training KNN...\n",
      "  Accuracy: 0.9625\n",
      "  F1-Score: 0.9691\n",
      "  CV Score: 0.9656 ± 0.0230\n",
      "\n",
      "Training Naive Bayes...\n",
      "  Accuracy: 0.9625\n",
      "  F1-Score: 0.9691\n",
      "  CV Score: 0.9281 ± 0.0351\n",
      "\n",
      "Training Decision Tree...\n",
      "  Accuracy: 0.9125\n",
      "  F1-Score: 0.9278\n",
      "  CV Score: 0.9437 ± 0.0272\n",
      "\n",
      "================================================================================\n",
      "MODEL PERFORMANCE COMPARISON\n",
      "================================================================================\n",
      "              Model  Accuracy  Precision  Recall  F1-Score  ROC-AUC  CV_Mean  CV_Std\n",
      "      Random Forest    1.0000     1.0000    1.00    1.0000   1.0000   0.9906  0.0125\n",
      "                SVM    0.9875     1.0000    0.98    0.9899   1.0000   0.9875  0.0117\n",
      "  Gradient Boosting    0.9750     1.0000    0.96    0.9796   1.0000   0.9781  0.0234\n",
      "Logistic Regression    0.9625     1.0000    0.94    0.9691   0.9920   0.9844  0.0171\n",
      "                KNN    0.9625     1.0000    0.94    0.9691   0.9900   0.9656  0.0230\n",
      "        Naive Bayes    0.9625     1.0000    0.94    0.9691   1.0000   0.9281  0.0351\n",
      "      Decision Tree    0.9125     0.9574    0.90    0.9278   0.9167   0.9438  0.0272\n"
     ]
    }
   ],
   "source": [
    "# 5. MODEL TRAINING & EVALUATION\n",
    "print(\"-\"*38)\n",
    "print(\"5. MODEL TRAINING & EVALUATION...\")\n",
    "print(\"-\"*38)\n",
    "\n",
    "# Define models to evaluate\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Storage for results\n",
    "results = []\n",
    "model_objects = {}\n",
    "\n",
    "print(\"Training and evaluating models...\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Choose scaled or unscaled data based on model type\n",
    "    if name in ['Logistic Regression', 'SVM', 'KNN', 'Naive Bayes']:\n",
    "        X_train_model = X_train_scaled\n",
    "        X_test_model = X_test_scaled\n",
    "    else:\n",
    "        X_train_model = X_train\n",
    "        X_test_model = X_test\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_model, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_model)\n",
    "    y_pred_proba = model.predict_proba(X_test_model)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # ROC-AUC if probability predictions available\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
    "    \n",
    "    # Cross-validation score\n",
    "    cv_scores = cross_val_score(model, X_train_model, y_train, cv=5, scoring='accuracy')\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'CV_Mean': cv_mean,\n",
    "        'CV_Std': cv_std\n",
    "    })\n",
    "    \n",
    "    # Store model object\n",
    "    model_objects[name] = model\n",
    "    \n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  F1-Score: {f1:.4f}\")\n",
    "    print(f\"  CV Score: {cv_mean:.4f} ± {cv_std:.4f}\")\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfbd4da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
