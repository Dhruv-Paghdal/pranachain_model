{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpUFFdbBQUii",
        "outputId": "0b955220-6a52-4e0d-c18d-24c3cda7030e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully into Colab.\n",
            "Original shape: (29002, 12)\n",
            "Original columns: ['SEQN', 'Age', 'Gender', 'Diabetes', 'FamilyHistory', 'BMI', 'SystolicBP', 'DiastolicBP', 'A1c', 'Glucose', 'TotalCholesterol', 'Triglycerides']\n",
            "\n",
            "First few rows:\n",
            "      SEQN   Age  Gender  Diabetes  FamilyHistory    BMI  SystolicBP  \\\n",
            "0  41479.0  52.0     1.0       2.0            2.0  27.56       112.0   \n",
            "1  41485.0  30.0     2.0       2.0            2.0  25.99       108.0   \n",
            "2  41486.0  61.0     2.0       2.0            2.0  31.21       126.0   \n",
            "3  41487.0  27.0     1.0       2.0            2.0  23.44       120.0   \n",
            "4  41489.0  40.0     2.0       2.0            2.0  36.59       106.0   \n",
            "\n",
            "   DiastolicBP  A1c  Glucose  TotalCholesterol  Triglycerides  \n",
            "0         70.0  5.7     96.2             188.0           84.0  \n",
            "1         44.0  5.5    104.8             188.0          172.0  \n",
            "2         64.0  6.1    103.2             194.0          233.0  \n",
            "3         84.0  5.0    113.0             167.0          124.0  \n",
            "4         66.0  5.4     97.8             188.0          101.0  \n",
            "\n",
            "Data types:\n",
            "SEQN                float64\n",
            "Age                 float64\n",
            "Gender              float64\n",
            "Diabetes            float64\n",
            "FamilyHistory       float64\n",
            "BMI                 float64\n",
            "SystolicBP          float64\n",
            "DiastolicBP         float64\n",
            "A1c                 float64\n",
            "Glucose             float64\n",
            "TotalCholesterol    float64\n",
            "Triglycerides       float64\n",
            "dtype: object\n",
            "\n",
            "Original Diabetes value counts:\n",
            "Diabetes\n",
            "2.0    27584\n",
            "1.0     1133\n",
            "3.0      285\n",
            "Name: count, dtype: int64\n",
            "\n",
            "============================================================\n",
            "CONVERTING TO BINARY CLASSIFICATION\n",
            "============================================================\n",
            "Mapping (CORRECTED for NHANES coding):\n",
            "  1.0 (Has Diabetes) → 1\n",
            "  2.0 (No Diabetes) → 0\n",
            "  3.0 (Borderline) → 1\n",
            "\n",
            "New binary Diabetes value counts:\n",
            "Diabetes\n",
            "0    27584\n",
            "1     1418\n",
            "Name: count, dtype: int64\n",
            "Class distribution: {0: 0.9511068202192953, 1: 0.04889317978070478}\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# CORRECTED TRAINING NOTEBOOK - Run this in Google Colab\n",
        "# Complete notebook for proper model training\n",
        "\n",
        "# ============================================\n",
        "# CELL 1: Load Data\n",
        "# ============================================\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# Read the uploaded file into a DataFrame\n",
        "filename = 'diabetes_clean.csv'\n",
        "df = pd.read_csv(filename)\n",
        "\n",
        "print(\"Dataset loaded successfully into Colab.\")\n",
        "print(f\"Original shape: {df.shape}\")\n",
        "print(f\"Original columns: {df.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "print(f\"\\nData types:\")\n",
        "print(df.dtypes)\n",
        "print(f\"\\nOriginal Diabetes value counts:\")\n",
        "print(df['Diabetes'].value_counts())\n",
        "\n",
        "# CRITICAL FIX: Convert to Binary Classification\n",
        "# Based on NHANES coding:\n",
        "# 1.0 = YES, has Diabetes → 1 (Positive class)\n",
        "# 2.0 = NO, does not have Diabetes → 0 (Negative class)\n",
        "# 3.0 = Borderline → 1 (Positive class - treat as \"at risk\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CONVERTING TO BINARY CLASSIFICATION\")\n",
        "print(\"=\"*60)\n",
        "print(\"Mapping (CORRECTED for NHANES coding):\")\n",
        "print(\"  1.0 (Has Diabetes) → 1\")\n",
        "print(\"  2.0 (No Diabetes) → 0\")\n",
        "print(\"  3.0 (Borderline) → 1\")\n",
        "\n",
        "df['Diabetes'] = df['Diabetes'].map({1.0: 1, 2.0: 0, 3.0: 1})\n",
        "\n",
        "print(f\"\\nNew binary Diabetes value counts:\")\n",
        "print(df['Diabetes'].value_counts())\n",
        "print(f\"Class distribution: {df['Diabetes'].value_counts(normalize=True).to_dict()}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Make a copy to avoid modifying original\n",
        "df_processed = df.copy()\n",
        "\n",
        "# --- Step 1: Separate Target Variable FIRST (CRITICAL!) ---\n",
        "# Remove target before any encoding to prevent data leakage\n",
        "y = df_processed['Diabetes']  # Save target\n",
        "X = df_processed.drop(columns=['SEQN', 'Diabetes'])  # Remove ID and target\n",
        "\n",
        "print(\"\\n=== Step 1: Separated Features and Target ===\")\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"Features: {X.columns.tolist()}\")\n",
        "\n",
        "# --- Step 2: Define columns to scale (numeric only) ---\n",
        "scaling_columns = [\n",
        "    \"Age\",\n",
        "    \"BMI\",\n",
        "    \"SystolicBP\",\n",
        "    \"DiastolicBP\",\n",
        "    \"A1c\",\n",
        "    \"Glucose\",\n",
        "    \"TotalCholesterol\",\n",
        "    \"Triglycerides\"\n",
        "]\n",
        "\n",
        "# --- Step 3: Scale numeric features ---\n",
        "scaler = StandardScaler()\n",
        "X[scaling_columns] = scaler.fit_transform(X[scaling_columns])\n",
        "\n",
        "print(\"\\n=== Step 2: Feature Scaling Applied ===\")\n",
        "print(\"Scaled columns:\", scaling_columns)\n",
        "\n",
        "# --- Step 4: One-Hot Encode Categorical Features ---\n",
        "# Only encode Gender and FamilyHistory (NOT Diabetes!)\n",
        "categorical_columns = [\"Gender\", \"FamilyHistory\"]\n",
        "X = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "print(\"\\n=== Step 3: One-Hot Encoding Applied ===\")\n",
        "print(f\"Shape after encoding: {X.shape}\")\n",
        "print(f\"Final features: {X.columns.tolist()}\")\n",
        "print(f\"Number of features: {X.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCJNl4-MQ_lQ",
        "outputId": "83ae92e1-cfcf-4b35-c9bc-6a0fba20f658"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Step 1: Separated Features and Target ===\n",
            "Features shape: (29002, 10)\n",
            "Target shape: (29002,)\n",
            "Features: ['Age', 'Gender', 'FamilyHistory', 'BMI', 'SystolicBP', 'DiastolicBP', 'A1c', 'Glucose', 'TotalCholesterol', 'Triglycerides']\n",
            "\n",
            "=== Step 2: Feature Scaling Applied ===\n",
            "Scaled columns: ['Age', 'BMI', 'SystolicBP', 'DiastolicBP', 'A1c', 'Glucose', 'TotalCholesterol', 'Triglycerides']\n",
            "\n",
            "=== Step 3: One-Hot Encoding Applied ===\n",
            "Shape after encoding: (29002, 10)\n",
            "Final features: ['Age', 'BMI', 'SystolicBP', 'DiastolicBP', 'A1c', 'Glucose', 'TotalCholesterol', 'Triglycerides', 'Gender_2.0', 'FamilyHistory_2.0']\n",
            "Number of features: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\n=== Train-Test Split ===\")\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "\n",
        "# Train the model\n",
        "model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=== Model Training Complete ===\")\n",
        "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Model expects {model.n_features_in_} features ✓\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzyOyBVVRPdY",
        "outputId": "c58ba903-326f-462a-a03d-263cf11bf33e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Train-Test Split ===\n",
            "Training set: (23201, 10)\n",
            "Test set: (5801, 10)\n",
            "\n",
            "=== Model Training Complete ===\n",
            "Logistic Regression Accuracy: 0.9633\n",
            "Model expects 10 features ✓\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
        "\n",
        "# First, check how many unique classes we have\n",
        "print(\"\\n=== Checking Target Variable ===\")\n",
        "print(f\"Unique values in y_test: {sorted(y_test.unique())}\")\n",
        "print(f\"Number of classes: {len(y_test.unique())}\")\n",
        "print(f\"Value counts:\\n{y_test.value_counts()}\")\n",
        "\n",
        "# Calculate metrics\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, zero_division=0)\n",
        "\n",
        "print(\"\\n=== Detailed Performance Metrics ===\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Calculate ROC AUC (handle both binary and multiclass)\n",
        "y_prob = model.predict_proba(X_test)\n",
        "if len(y_test.unique()) == 2:\n",
        "    # Binary classification\n",
        "    roc_auc = roc_auc_score(y_test, y_prob[:, 1])\n",
        "    print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
        "else:\n",
        "    # Multiclass - use ovr (one-vs-rest) strategy\n",
        "    roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr', average='weighted')\n",
        "    print(f\"ROC AUC Score (weighted): {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQlc7JE8Rko1",
        "outputId": "34c33b94-6c9a-4ddf-d845-94fa8cca137e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Checking Target Variable ===\n",
            "Unique values in y_test: [np.int64(0), np.int64(1)]\n",
            "Number of classes: 2\n",
            "Value counts:\n",
            "Diabetes\n",
            "0    5517\n",
            "1     284\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Detailed Performance Metrics ===\n",
            "\n",
            "Confusion Matrix:\n",
            "[[5491   26]\n",
            " [ 187   97]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98      5517\n",
            "           1       0.79      0.34      0.48       284\n",
            "\n",
            "    accuracy                           0.96      5801\n",
            "   macro avg       0.88      0.67      0.73      5801\n",
            "weighted avg       0.96      0.96      0.96      5801\n",
            "\n",
            "ROC AUC Score: 0.9299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Define the optimized threshold\n",
        "NEW_THRESHOLD = 0.4\n",
        "\n",
        "# For binary classification, use threshold on probability of positive class\n",
        "if len(y_test.unique()) == 2:\n",
        "    # Get probability of the positive class (higher value)\n",
        "    positive_class = sorted(y_test.unique())[1]\n",
        "    positive_class_idx = list(model.classes_).index(positive_class)\n",
        "    y_prob_positive = y_prob[:, positive_class_idx]\n",
        "\n",
        "    # Generate predictions using the new threshold\n",
        "    y_pred_threshold = (y_prob_positive >= NEW_THRESHOLD).astype(int)\n",
        "    # Map back to original class labels\n",
        "    y_pred_threshold = [sorted(y_test.unique())[i] for i in y_pred_threshold]\n",
        "else:\n",
        "    # For multiclass, just use standard prediction\n",
        "    y_pred_threshold = y_pred\n",
        "    print(\"Note: Threshold adjustment only works for binary classification.\")\n",
        "\n",
        "# Evaluate with new threshold\n",
        "print(f\"\\n=== Model Evaluation with Threshold = {NEW_THRESHOLD} ===\")\n",
        "\n",
        "cm_threshold = confusion_matrix(y_test, y_pred_threshold)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm_threshold)\n",
        "\n",
        "report_threshold = classification_report(y_test, y_pred_threshold, zero_division=0)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report_threshold)\n",
        "\n",
        "if len(y_test.unique()) == 2:\n",
        "    roc_auc_threshold = roc_auc_score(y_test, y_prob_positive)\n",
        "    print(f\"ROC AUC Score: {roc_auc_threshold:.4f}\")\n",
        "else:\n",
        "    print(f\"ROC AUC Score: {roc_auc:.4f} (unchanged)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14qC1rerR7AE",
        "outputId": "312e9d84-0444-4157-c223-e532380c56c2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Model Evaluation with Threshold = 0.4 ===\n",
            "\n",
            "Confusion Matrix:\n",
            "[[5476   41]\n",
            " [ 170  114]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      5517\n",
            "           1       0.74      0.40      0.52       284\n",
            "\n",
            "    accuracy                           0.96      5801\n",
            "   macro avg       0.85      0.70      0.75      5801\n",
            "weighted avg       0.96      0.96      0.96      5801\n",
            "\n",
            "ROC AUC Score: 0.9299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define paths\n",
        "SAVE_DIR = '/content/'\n",
        "model_path = SAVE_DIR + \"final_lr_model.joblib\"\n",
        "scaler_path = SAVE_DIR + \"final_scaler.joblib\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING FINAL MODEL ON COMPLETE DATASET\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# --- Reload and process complete dataset ---\n",
        "df_full = pd.read_csv(filename)\n",
        "\n",
        "# Separate target\n",
        "y_full = df_full['Diabetes']\n",
        "X_full = df_full.drop(columns=['SEQN', 'Diabetes'])\n",
        "\n",
        "print(f\"\\nFull dataset shape: {X_full.shape}\")\n",
        "\n",
        "# Create new scaler and fit on full data\n",
        "final_scaler = StandardScaler()\n",
        "X_full[scaling_columns] = final_scaler.fit_transform(X_full[scaling_columns])\n",
        "\n",
        "# One-hot encode\n",
        "X_full = pd.get_dummies(X_full, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "print(f\"\\nProcessed full dataset:\")\n",
        "print(f\"  Shape: {X_full.shape}\")\n",
        "print(f\"  Features: {X_full.columns.tolist()}\")\n",
        "print(f\"  Number of features: {X_full.shape[1]}\")\n",
        "\n",
        "# Train final model\n",
        "print(\"\\nTraining final model...\")\n",
        "final_model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "final_model.fit(X_full, y_full)\n",
        "print(\"✓ Training complete!\")\n",
        "print(f\"✓ Model trained with {final_model.n_features_in_} features\")\n",
        "\n",
        "# Save model and scaler\n",
        "joblib.dump(final_model, model_path)\n",
        "print(f\"\\n✅ Model saved to: {model_path}\")\n",
        "\n",
        "joblib.dump(final_scaler, scaler_path)\n",
        "print(f\"✅ Scaler saved to: {scaler_path}\")\n",
        "\n",
        "# Display feature list for Streamlit app\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COPY THIS TO YOUR STREAMLIT APP (app.py):\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nFINAL_MODEL_FEATURES = [\")\n",
        "for feature in X_full.columns:\n",
        "    print(f\"    '{feature}',\")\n",
        "print(\"]\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "print(\"\\n✨ Model and scaler are ready for deployment!\")\n",
        "print(\"\\nDownloading files...\")\n",
        "\n",
        "# Download the files\n",
        "try:\n",
        "    files.download(model_path)\n",
        "    files.download(scaler_path)\n",
        "    print(\"✓ Files downloaded successfully!\")\n",
        "except:\n",
        "    print(\"Note: Files saved in Colab. Download manually if needed.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"NEXT STEPS:\")\n",
        "print(\"=\"*60)\n",
        "print(\"1. Upload the downloaded .joblib files to your Streamlit app\")\n",
        "print(\"2. Update FINAL_MODEL_FEATURES in app.py with the list above\")\n",
        "print(\"3. Run your Streamlit app!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "id": "fjtVwhFqTkQP",
        "outputId": "00b68b9c-8156-4a9b-aa0b-40d7d5590793"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TRAINING FINAL MODEL ON COMPLETE DATASET\n",
            "============================================================\n",
            "\n",
            "Full dataset shape: (29002, 10)\n",
            "\n",
            "Processed full dataset:\n",
            "  Shape: (29002, 10)\n",
            "  Features: ['Age', 'BMI', 'SystolicBP', 'DiastolicBP', 'A1c', 'Glucose', 'TotalCholesterol', 'Triglycerides', 'Gender_2.0', 'FamilyHistory_2.0']\n",
            "  Number of features: 10\n",
            "\n",
            "Training final model...\n",
            "✓ Training complete!\n",
            "✓ Model trained with 10 features\n",
            "\n",
            "✅ Model saved to: /content/final_lr_model.joblib\n",
            "✅ Scaler saved to: /content/final_scaler.joblib\n",
            "\n",
            "============================================================\n",
            "COPY THIS TO YOUR STREAMLIT APP (app.py):\n",
            "============================================================\n",
            "\n",
            "FINAL_MODEL_FEATURES = [\n",
            "    'Age',\n",
            "    'BMI',\n",
            "    'SystolicBP',\n",
            "    'DiastolicBP',\n",
            "    'A1c',\n",
            "    'Glucose',\n",
            "    'TotalCholesterol',\n",
            "    'Triglycerides',\n",
            "    'Gender_2.0',\n",
            "    'FamilyHistory_2.0',\n",
            "]\n",
            "\n",
            "============================================================\n",
            "\n",
            "✨ Model and scaler are ready for deployment!\n",
            "\n",
            "Downloading files...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8701346d-da08-4611-8a01-20a27c08f901\", \"final_lr_model.joblib\", 1507)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cb6ebb1a-d18d-45c1-9299-87a3986488d3\", \"final_scaler.joblib\", 1143)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Files downloaded successfully!\n",
            "\n",
            "============================================================\n",
            "NEXT STEPS:\n",
            "============================================================\n",
            "1. Upload the downloaded .joblib files to your Streamlit app\n",
            "2. Update FINAL_MODEL_FEATURES in app.py with the list above\n",
            "3. Run your Streamlit app!\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}