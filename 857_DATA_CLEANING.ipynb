{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3487dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c72e03b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "dataset_857 = fetch_ucirepo(id=857)\n",
    "df_857 = pd.concat([dataset_857.data.features, dataset_857.data.targets], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9948c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\n",
    "    # Demographics\n",
    "    \"age\",\n",
    "    \n",
    "    # Clinical conditions\n",
    "    \"htn\",      # Hypertension\n",
    "    \"dm\",       # Diabetes Mellitus\n",
    "    \"cad\",      # Coronary Artery Disease\n",
    "    \n",
    "    # Urine tests\n",
    "    \"su\",       # Sugar\n",
    "    \"sg\",       # Specific Gravity\n",
    "    \"al\",       # Albumin\n",
    "    \n",
    "    # Blood tests\n",
    "    \"sc\",       # Serum Creatinine\n",
    "    \"grf\",      # Glomerular Filtration Rate (eGFR)\n",
    "    \"hemo\",     # Hemoglobin\n",
    "    \"rbcc\",     # Red Blood Cell Count\n",
    "    \n",
    "    # Target variable\n",
    "    \"class\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab24bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age  htn  dm  cad   su             sg     al      sc                grf  \\\n",
      "0    < 12    0   0    0  < 0  1.019 - 1.021  1-Jan  < 3.65          ≥ 227.944   \n",
      "1    < 12    0   0    0  < 0  1.009 - 1.011    < 0  < 3.65          ≥ 227.944   \n",
      "2    < 12    0   0    0  < 0  1.009 - 1.011    ≥ 4  < 3.65  127.281 - 152.446   \n",
      "3    < 12    0   0    0  < 0  1.009 - 1.011  3-Mar  < 3.65  127.281 - 152.446   \n",
      "4  20-Dec    0   1    0  < 0  1.015 - 1.017    < 0  < 3.65  127.281 - 152.446   \n",
      "5  20-Dec    0   0    0  < 0        ≥ 1.023    < 0  < 3.65  102.115 - 127.281   \n",
      "\n",
      "          hemo         rbcc   class  \n",
      "0  11.3 - 12.6  4.46 - 5.05     ckd  \n",
      "1  11.3 - 12.6  4.46 - 5.05     ckd  \n",
      "2     8.7 - 10  4.46 - 5.05     ckd  \n",
      "3  13.9 - 15.2  4.46 - 5.05     ckd  \n",
      "4  13.9 - 15.2  5.05 - 5.64     ckd  \n",
      "5       ≥ 16.5  5.05 - 5.64  notckd  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(df_857[col].head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "495ee583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in 'age':\n",
      "['< 12' '20-Dec' '20 - 27' '27 - 35' '35 - 43' '43 - 51' '51 - 59'\n",
      " '59 - 66' '66 - 74' '≥ 74']\n",
      "Count: 10\n",
      "\n",
      "Unique values in 'htn':\n",
      "[0 1]\n",
      "Count: 2\n",
      "\n",
      "Unique values in 'dm':\n",
      "[0 1]\n",
      "Count: 2\n",
      "\n",
      "Unique values in 'cad':\n",
      "[0 1]\n",
      "Count: 2\n",
      "\n",
      "Unique values in 'su':\n",
      "['< 0' '4-Apr' '2-Feb' '4-Mar' '2-Jan' '≥ 4']\n",
      "Count: 6\n",
      "\n",
      "Unique values in 'sg':\n",
      "['1.019 - 1.021' '1.009 - 1.011' '1.015 - 1.017' '≥ 1.023' '< 1.007']\n",
      "Count: 5\n",
      "\n",
      "Unique values in 'al':\n",
      "['1-Jan' '< 0' '≥ 4' '3-Mar' '2-Feb']\n",
      "Count: 5\n",
      "\n",
      "Unique values in 'sc':\n",
      "['< 3.65' '3.65 - 6.8' '16.25 - 19.4' '6.8 - 9.95' '13.1 - 16.25'\n",
      " '9.95 - 13.1' '≥ 28.85']\n",
      "Count: 7\n",
      "\n",
      "Unique values in 'grf':\n",
      "['≥ 227.944' '127.281 - 152.446' '102.115 - 127.281' '177.612 - 202.778'\n",
      " '26.6175 - 51.7832' '51.7832 - 76.949' '76.949 - 102.115'\n",
      " '152.446 - 177.612' '202.778 - 227.944' '< 26.6175' ' p ']\n",
      "Count: 11\n",
      "\n",
      "Unique values in 'hemo':\n",
      "['11.3 - 12.6' '8.7 - 10' '13.9 - 15.2' '≥ 16.5' '10 - 11.3' '7.4 - 8.7'\n",
      " '12.6 - 13.9' '15.2 - 16.5' '< 6.1' '6.1 - 7.4']\n",
      "Count: 10\n",
      "\n",
      "Unique values in 'rbcc':\n",
      "['4.46 - 5.05' '5.05 - 5.64' '3.28 - 3.87' '3.87 - 4.46' '6.23 - 6.82'\n",
      " '5.64 - 6.23' '2.69 - 3.28' '< 2.69' '≥ 7.41']\n",
      "Count: 9\n",
      "\n",
      "Unique values in 'class':\n",
      "['ckd' 'notckd']\n",
      "Count: 2\n"
     ]
    }
   ],
   "source": [
    "for column in col:\n",
    "    print(f\"\\nUnique values in '{column}':\")\n",
    "    print(df_857[column].unique())\n",
    "    print(f\"Count: {df_857[column].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "647e87ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sugar_mapping = {\n",
    "    '< 0': 0,\n",
    "    '≥ 4': 4,      # or 5, depending on your scale\n",
    "    '4-Apr': 4,\n",
    "    '4-Mar': 3,\n",
    "    '2-Feb': 2,\n",
    "    '2-Jan': 1,\n",
    "    # Also handle possible variations\n",
    "    '<0': 0,\n",
    "    '>=4': 4,\n",
    "    '≥4': 4,\n",
    "    # Handle if already numeric strings\n",
    "    '0': 0,\n",
    "    '1': 1,\n",
    "    '2': 2,\n",
    "    '3': 3,\n",
    "    '4': 4,\n",
    "    '5': 5,\n",
    "}\n",
    "df_857['su'] = df_857['su'].astype(str).str.strip()  # Clean whitespace\n",
    "df_857['su'] = df_857['su'].replace(sugar_mapping)\n",
    "df_857['su'] = pd.to_numeric(df_857['su'], errors='coerce')\n",
    "for idx in df_857[df_857['su'].isnull()].index:\n",
    "    if df_857.loc[idx, 'dm'] == 1:  \n",
    "        df_857.loc[idx, 'su'] = df_857[df_857['dm'] == 1]['su'].mode()[0]\n",
    "    else:\n",
    "        df_857.loc[idx, 'su'] = 0\n",
    "df_857['su'] = df_857['su'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0134d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_mapping = {\n",
    "    '< 1.007': 1.005,      # Severe impairment\n",
    "    '1.009 - 1.011': 1.010, # Mild impairment\n",
    "    '1.015 - 1.017': 1.016, # Normal\n",
    "    '1.019 - 1.021': 1.020, # Normal/concentrated\n",
    "    '≥ 1.023': 1.025,       # Concentrated\n",
    "    # Handle variations\n",
    "    '<1.007': 1.005,\n",
    "    '>=1.023': 1.025,\n",
    "    '≥1.023': 1.025,\n",
    "}\n",
    "\n",
    "# Step 2: Apply mapping\n",
    "df_857['sg'] = df_857['sg'].astype(str).str.strip()\n",
    "df_857['sg'] = df_857['sg'].replace(sg_mapping)\n",
    "\n",
    "# Step 3: Convert to float\n",
    "df_857['sg'] = pd.to_numeric(df_857['sg'], errors='coerce')\n",
    "\n",
    "# Step 4: Handle missing values with median\n",
    "df_857['sg'].fillna(df_857['sg'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e1a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbcc_mapping = {\n",
    "    '< 2.69': 2.40,           # Severe anemia\n",
    "    '2.69 - 3.28': 2.985,     # Moderate anemia\n",
    "    '3.28 - 3.87': 3.575,     # Mild anemia\n",
    "    '3.87 - 4.46': 4.165,     # Low normal\n",
    "    '4.46 - 5.05': 4.755,     # Normal\n",
    "    '5.05 - 5.64': 5.345,     # Normal\n",
    "    '5.64 - 6.23': 5.935,     # Normal/high\n",
    "    '6.23 - 6.82': 6.525,     # High\n",
    "    '≥ 7.41': 7.70,           # Polycythemia\n",
    "    # Handle variations\n",
    "    '<2.69': 2.40,\n",
    "    '>=7.41': 7.70,\n",
    "    '≥7.41': 7.70,\n",
    "}\n",
    "\n",
    "# Apply mapping\n",
    "df_857['rbcc'] = df_857['rbcc'].astype(str).str.strip()\n",
    "df_857['rbcc'] = df_857['rbcc'].replace(rbcc_mapping)\n",
    "df_857['rbcc'] = pd.to_numeric(df_857['rbcc'], errors='coerce')\n",
    "\n",
    "# Impute missing values\n",
    "df_857['rbcc'].fillna(df_857['rbcc'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea2cdbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mapping = {\n",
    "    '< 12': 10,\n",
    "    '20-Dec': 16,      # Excel corruption of \"12-20\"\n",
    "    '12-Dec': 16,\n",
    "    '20 - 27': 24,\n",
    "    '27 - 35': 31,\n",
    "    '35 - 43': 39,\n",
    "    '43 - 51': 47,\n",
    "    '51 - 59': 55,\n",
    "    '59 - 66': 63,\n",
    "    '66 - 74': 70,\n",
    "    '≥ 74': 77,\n",
    "}\n",
    "\n",
    "# Clean\n",
    "df_857['age'] = df_857['age'].astype(str).str.strip()\n",
    "df_857['age'] = df_857['age'].replace(age_mapping)\n",
    "df_857['age'] = pd.to_numeric(df_857['age'], errors='coerce')\n",
    "df_857['age'].fillna(df_857['age'].median(), inplace=True)\n",
    "df_857['age'] = df_857['age'].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "567ca1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "albumin_mapping = {\n",
    "    '< 0': 0,\n",
    "    '1-Jan': 1,\n",
    "    '2-Feb': 2,\n",
    "    '3-Mar': 3,\n",
    "    '4-Apr': 4,\n",
    "    '≥ 4': 4,\n",
    "    '5-May': 5,\n",
    "}\n",
    "\n",
    "df_857['al'] = df_857['al'].astype(str).str.strip()\n",
    "df_857['al'] = df_857['al'].replace(albumin_mapping)\n",
    "df_857['al'] = pd.to_numeric(df_857['al'], errors='coerce')\n",
    "df_857['al'].fillna(df_857['al'].median(), inplace=True)\n",
    "df_857['al'] = df_857['al'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e177ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_mapping = {\n",
    "    '< 3.65': 3.15,          # Near normal (below mild impairment)\n",
    "    '3.65 - 6.8': 5.225,     # Moderate kidney impairment\n",
    "    '6.8 - 9.95': 8.375,     # Severe kidney impairment\n",
    "    '9.95 - 13.1': 11.525,   # Very severe impairment\n",
    "    '13.1 - 16.25': 14.675,  # Advanced kidney failure\n",
    "    '16.25 - 19.4': 17.825,  # End-stage kidney disease\n",
    "    '≥ 28.85': 29.85,        # Critical kidney failure\n",
    "    # Handle variations\n",
    "    '<3.65': 3.15,\n",
    "    '>=28.85': 29.85,\n",
    "    '≥28.85': 29.85,\n",
    "}\n",
    "\n",
    "# Apply mapping\n",
    "df_857['sc'] = df_857['sc'].astype(str).str.strip()\n",
    "df_857['sc'] = df_857['sc'].replace(sc_mapping)\n",
    "df_857['sc'] = pd.to_numeric(df_857['sc'], errors='coerce')\n",
    "\n",
    "# Impute missing values\n",
    "df_857['sc'] = df_857['sc'].fillna(df_857['sc'].median()).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc0d5bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hemo_mapping = {\n",
    "    '< 6.1': 5.6,          # Life-threatening anemia\n",
    "    '6.1 - 7.4': 6.75,     # Severe anemia\n",
    "    '7.4 - 8.7': 8.05,     # Severe anemia\n",
    "    '8.7 - 10': 9.35,      # Moderate anemia\n",
    "    '10 - 11.3': 10.65,    # Moderate anemia\n",
    "    '11.3 - 12.6': 11.95,  # Mild anemia\n",
    "    '12.6 - 13.9': 13.25,  # Low normal to mild anemia\n",
    "    '13.9 - 15.2': 14.55,  # Normal\n",
    "    '15.2 - 16.5': 15.85,  # Normal\n",
    "    '≥ 16.5': 17.0,        # Normal/high\n",
    "    # Handle variations\n",
    "    '<6.1': 5.6,\n",
    "    '>=16.5': 17.0,\n",
    "    '≥16.5': 17.0,\n",
    "}\n",
    "\n",
    "# Apply mapping\n",
    "df_857['hemo'] = df_857['hemo'].astype(str).str.strip()\n",
    "df_857['hemo'] = df_857['hemo'].replace(hemo_mapping)\n",
    "df_857['hemo'] = pd.to_numeric(df_857['hemo'], errors='coerce')\n",
    "\n",
    "# Impute missing values\n",
    "df_857['hemo'] = df_857['hemo'].fillna(df_857['hemo'].median()).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a65f7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "grf_mapping = {\n",
    "    ' p ': np.nan,              # Corrupted data\n",
    "    'p': np.nan,\n",
    "    '< 26.6175': 21.62,         # Stage 5: Kidney failure\n",
    "    '26.6175 - 51.7832': 39.20, # Stage 4: Severe impairment\n",
    "    '51.7832 - 76.949': 64.37,  # Stage 3b: Moderate-severe impairment\n",
    "    '76.949 - 102.115': 89.53,  # Stage 2-3a: Mild-moderate impairment\n",
    "    '102.115 - 127.281': 114.70, # Stage 2: Mild impairment\n",
    "    '127.281 - 152.446': 139.86, # Stage 1-2: Normal to mild\n",
    "    '152.446 - 177.612': 165.03, # Stage 1: Normal\n",
    "    '177.612 - 202.778': 190.20, # Stage 1: Normal/high\n",
    "    '202.778 - 227.944': 215.36, # Stage 1: High\n",
    "    '≥ 227.944': 237.94,         # Very high (hyperfiltration)\n",
    "    # Handle variations\n",
    "    '<26.6175': 21.62,\n",
    "    '>=227.944': 237.94,\n",
    "    '≥227.944': 237.94,\n",
    "}\n",
    "\n",
    "# Apply mapping\n",
    "df_857['grf'] = df_857['grf'].astype(str).str.strip()\n",
    "df_857['grf'] = df_857['grf'].replace(grf_mapping)\n",
    "df_857['grf'] = pd.to_numeric(df_857['grf'], errors='coerce')\n",
    "\n",
    "# Impute missing values\n",
    "df_857['grf'] = df_857['grf'].fillna(df_857['grf'].median()).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6548ab18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in 'age':\n",
      "[10 16 24 31 39 47 55 63 70 77]\n",
      "Count: 10\n",
      "\n",
      "Unique values in 'htn':\n",
      "[0 1]\n",
      "Count: 2\n",
      "\n",
      "Unique values in 'dm':\n",
      "[0 1]\n",
      "Count: 2\n",
      "\n",
      "Unique values in 'cad':\n",
      "[0 1]\n",
      "Count: 2\n",
      "\n",
      "Unique values in 'su':\n",
      "[0. 4. 2. 3. 1.]\n",
      "Count: 5\n",
      "\n",
      "Unique values in 'sg':\n",
      "[1.02  1.01  1.016 1.025 1.005]\n",
      "Count: 5\n",
      "\n",
      "Unique values in 'al':\n",
      "[1. 0. 4. 3. 2.]\n",
      "Count: 5\n",
      "\n",
      "Unique values in 'sc':\n",
      "[ 3.15   5.225 17.825  8.375 14.675 11.525 29.85 ]\n",
      "Count: 7\n",
      "\n",
      "Unique values in 'grf':\n",
      "[237.94 139.86 114.7  190.2   39.2   64.37  89.53 165.03 215.36  21.62]\n",
      "Count: 10\n",
      "\n",
      "Unique values in 'hemo':\n",
      "[11.95  9.35 14.55 17.   10.65  8.05 13.25 15.85  5.6   6.75]\n",
      "Count: 10\n",
      "\n",
      "Unique values in 'rbcc':\n",
      "[4.755 5.345 3.575 4.165 6.525 5.935 2.985 2.4   7.7  ]\n",
      "Count: 9\n",
      "\n",
      "Unique values in 'class':\n",
      "['ckd' 'notckd']\n",
      "Count: 2\n"
     ]
    }
   ],
   "source": [
    "for column in col:\n",
    "    print(f\"\\nUnique values in '{column}':\")\n",
    "    print(df_857[column].unique())\n",
    "    print(f\"Count: {df_857[column].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40c44e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_857['class'] = df_857['class'].str.strip()\n",
    "df_857['class'] = df_857['class'].str.lower()\n",
    "df_857['class'] = df_857['class'].map({'ckd': 1, 'notckd': 0})\n",
    "df_export = df_857[col]\n",
    "df_export = df_export.rename(columns={'grf': 'gfr'})\n",
    "df_export.to_csv('UCI_857_Cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82b931fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"UCI_857_Cleaned.csv\"\n",
    "\n",
    "NOISE_FACTOR = 0.05  \n",
    "TARGET_CLASS_COUNT = 200 \n",
    "\n",
    "CONTINUOUS_COLS = ['age', 'sc', 'gfr', 'hemo', 'rbcc'] \n",
    "DISCRETE_COLS = ['htn', 'dm', 'cad', 'su', 'sg', 'al'] \n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}. Please ensure the file is available.\")\n",
    "        return None\n",
    "\n",
    "    for col in DISCRETE_COLS:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        mode_val = df[col].mode()[0]\n",
    "        df[col] = df[col].fillna(mode_val).astype(int)\n",
    "\n",
    "    for col in CONTINUOUS_COLS:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        median_val = df[col].median()\n",
    "        df[col] = df[col].fillna(median_val)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def augment_continuous_features(X_continuous, noise_factor):\n",
    "    std_devs = X_continuous.std(axis=0)\n",
    "    \n",
    "    std_devs[std_devs == 0] = 1e-6 \n",
    "    \n",
    "    noise = np.random.normal(loc=0.0, scale=1.0, size=X_continuous.shape)\n",
    "    scaled_noise = noise * std_devs * noise_factor\n",
    "    \n",
    "    X_augmented = X_continuous + scaled_noise\n",
    "    return X_augmented\n",
    "\n",
    "def perform_oversampling(df_original):\n",
    "    df_class_0 = df_original[df_original['class'] == 0].drop(columns=['class'])\n",
    "    df_class_1 = df_original[df_original['class'] == 1].drop(columns=['class'])\n",
    "\n",
    "    n_augment_0 = TARGET_CLASS_COUNT - len(df_class_0)\n",
    "    n_augment_1 = TARGET_CLASS_COUNT - len(df_class_1)\n",
    "    \n",
    "    all_features = CONTINUOUS_COLS + DISCRETE_COLS\n",
    "    \n",
    "    def generate_augmented_data(df_class, n_augment, target_class):\n",
    "        if n_augment <= 0:\n",
    "            return pd.DataFrame() \n",
    "\n",
    "        sample_indices = np.random.choice(len(df_class), size=n_augment, replace=True)\n",
    "        \n",
    "        X_continuous = df_class[CONTINUOUS_COLS].iloc[sample_indices].values\n",
    "        X_discrete = df_class[DISCRETE_COLS].iloc[sample_indices].values\n",
    "        \n",
    "        X_aug_continuous = augment_continuous_features(X_continuous, NOISE_FACTOR)\n",
    "        \n",
    "        df_aug_continuous = pd.DataFrame(X_aug_continuous, columns=CONTINUOUS_COLS)\n",
    "        df_aug_discrete = pd.DataFrame(X_discrete, columns=DISCRETE_COLS)\n",
    "        \n",
    "        for col in DISCRETE_COLS:\n",
    "            df_aug_discrete[col] = df_aug_discrete[col].astype(int)\n",
    "        \n",
    "        df_aug = pd.concat([df_aug_continuous, df_aug_discrete], axis=1)\n",
    "        df_aug = df_aug[all_features] \n",
    "        df_aug['class'] = target_class\n",
    "        \n",
    "        return df_aug\n",
    "\n",
    "    df_aug_0 = generate_augmented_data(df_class_0, n_augment_0, 0)\n",
    "    \n",
    "    df_aug_1 = generate_augmented_data(df_class_1, n_augment_1, 1)\n",
    "\n",
    "    df_augmented = pd.concat([df_aug_0, df_aug_1], ignore_index=True)\n",
    "    \n",
    "    df_final = pd.concat([df_original, df_augmented], ignore_index=True)\n",
    "    \n",
    "    return df_final, df_augmented\n",
    "\n",
    "initial_df = load_and_preprocess_data(FILE_PATH)\n",
    "\n",
    "if initial_df is not None:\n",
    "    final_df, augmented_df = perform_oversampling(initial_df)\n",
    "\n",
    "final_df.to_csv('UCI_857_Augmented.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
